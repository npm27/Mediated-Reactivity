temp = t.test(combined.direction$F, combined.direction$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(combined.direction$F, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#U vs M
temp = t.test(combined.direction$M, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#Not surprisingly, everything is sig!
###Interaction
jol3 = subset(combined, combined$encoding == "JOL")
read3 = subset(combined, combined$encoding == "Read")
jol.ph = cast(jol3, id ~ direction, mean)
read.ph = cast(read3, id ~ direction, mean)
(apply(jol.ph[ , -1], 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph[ , -1], 2, sd) / sqrt(nrow(read.ph))) * 1.96
##forward
temp = t.test(jol.ph$F, read.ph$F, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Significant! p = .018
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#unrelated
temp = t.test(jol.ph$U, read.ph$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Non-Sig
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#okay, so trending in the right direction!
##get ns after cleaning
##get N
nrow(jol.ph) #55
nrow(read.ph) #55
##How many from each platform?
jol4 = subset(jol3,
jol3$Platform == "Prolific")
length(unique(jol4$id)) #21
jol5 = subset(jol3,
jol3$Platform == "USM")
length(unique(jol5$id)) #34
read4 = subset(read3,
read3$Platform == "Prolific")
length(unique(read4$id)) #22
read5 = subset(read3,
read3$Platform == "USM")
length(unique(read5$id)) #33
####platform differences?####
combined2 = rbind(jol4, read4)
combined3 = rbind(jol5, read5)
tapply(combined2$score, list(combined2$encoding, combined2$direction), mean)
tapply(combined3$score, list(combined3$encoding, combined3$direction), mean) #Not really, its about 8% increase.
tapply(combined$score, list(combined$encoding, combined$direction), mean) #interaction
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
temp$statistic #Significant! p = .013
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#now write to .csv for scoring
length(unique(JOL$Username)) #25
length(unique(Study$Username)) #23
##read in data
JOL = rbind(read.csv("USM/JOL Scored.csv"), read.csv("Prolific/JOL Scored_P.csv"))
Read = rbind(read.csv("USM/Read Scored.csv"), read.csv("Prolific/Read Scored_P.csv"))
#load libraries
library(reshape)
library(ez)
library(psychReport)
#turn off scientific notation
options(scipen = 999)
##drop unused columns
JOL2 = JOL[ , -c(2:4, 8:9, 11:14)]
Read2 = Read[ , -c(2:4, 8:9, 11:13)]
#slap together and rearrange columns
combined = rbind(JOL2, Read2)
combined = combined[ , c(1, 3, 4, 5, 6, 2)]
#rename columns
colnames(combined)[c(3:4, 6)] = c("encoding", "direction", "score")
combined$encoding[combined$encoding == "JOL Recall"] = "JOL"
combined$encoding[combined$encoding == "Read Recall"] = "Read"
#get score on correct scale
combined$score = combined$score * 100
tapply(combined$score, list(combined$encoding, combined$direction), mean, na.omit = T)
##Check for outliers and weirdness here
summary(combined)
JOL3 = subset(combined,
combined$encoding == "JOL")
Read3 = subset(combined,
combined$encoding == "Read")
JOL.wide = cast(JOL3, id ~ direction, mean)
Read.wide = cast(Read3, id ~ direction, mean)
combined = subset(combined,
combined$id != "W10057641NS" & combined$id != "10068469SJ" & combined$id != "W_10132867_LAA" &
combined$id != "62f17b6b63bd9e6627a19956" & combined$id != "5a8b1ee2000dab00018cc7cd" &
combined$id != "62d43cee3d60ac98c1dcacc8" & combined$id != "63474e67a5fd298c6103c409" &
combined$id != "w963035" & combined$id != "5c2bb03b9fb36d000198e2d7" & combined$id != "w10162630_CAG" &
combined$id != "TaravionCosey" & combined$id != "w10055946")
####ANOVA####
model1 = ezANOVA(combined,
dv = score,
between = encoding,
within = direction,
wid = id,
type = 3,
detailed = T)
model1 #basically everything is sig!
####Post-hocs####
tapply(combined$score, combined$encoding, mean) #main effect of encoding
tapply(combined$score, combined$direction, mean) #main effect of direction
tapply(combined$score, list(combined$encoding, combined$direction), mean) #interaction
(tapply(combined$score, list(combined$encoding, combined$direction), sd) / sqrt(length(unique(combined$id)))) * 1.96
###break down direction main effect
combined.direction = cast(combined, id ~ direction, mean)
#F vs M
temp = t.test(combined.direction$F, combined.direction$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(combined.direction$F, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#U vs M
temp = t.test(combined.direction$M, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#Not surprisingly, everything is sig!
###Interaction
jol3 = subset(combined, combined$encoding == "JOL")
read3 = subset(combined, combined$encoding == "Read")
jol.ph = cast(jol3, id ~ direction, mean)
read.ph = cast(read3, id ~ direction, mean)
(apply(jol.ph[ , -1], 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph[ , -1], 2, sd) / sqrt(nrow(read.ph))) * 1.96
##forward
temp = t.test(jol.ph$F, read.ph$F, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Significant! p = .013
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#unrelated
temp = t.test(jol.ph$U, read.ph$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Non-Sig
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#okay, so trending in the right direction!
##get ns after cleaning
##get N
nrow(jol.ph) #55
nrow(read.ph) #55
##How many from each platform?
jol4 = subset(jol3,
jol3$Platform == "Prolific")
length(unique(jol4$id)) #21
jol5 = subset(jol3,
jol3$Platform == "USM")
length(unique(jol5$id)) #34
read4 = subset(read3,
read3$Platform == "Prolific")
length(unique(read4$id)) #22
read5 = subset(read3,
read3$Platform == "USM")
length(unique(read5$id)) #33
####platform differences?####
combined2 = rbind(jol4, read4)
combined3 = rbind(jol5, read5)
tapply(combined2$score, list(combined2$encoding, combined2$direction), mean)
tapply(combined3$score, list(combined3$encoding, combined3$direction), mean) #Not really, its about 8% increase.
length(unique(read5$id)) #33
length(unique(jol5$id)) #34
length(unique(jol4$id)) #21
##get ns after cleaning
##get N
nrow(jol.ph) #55
nrow(read.ph) #55
##read in data
JOL = rbind(read.csv("USM/JOL Scored.csv"), read.csv("Prolific/JOL Scored_P.csv"))
Read = rbind(read.csv("USM/Read Scored.csv"), read.csv("Prolific/Read Scored_P.csv"))
#load libraries
library(reshape)
library(ez)
library(psychReport)
#turn off scientific notation
options(scipen = 999)
##drop unused columns
JOL2 = JOL[ , -c(2:4, 8:9, 11:14)]
Read2 = Read[ , -c(2:4, 8:9, 11:13)]
#slap together and rearrange columns
combined = rbind(JOL2, Read2)
combined = combined[ , c(1, 3, 4, 5, 6, 2)]
#rename columns
colnames(combined)[c(3:4, 6)] = c("encoding", "direction", "score")
combined$encoding[combined$encoding == "JOL Recall"] = "JOL"
combined$encoding[combined$encoding == "Read Recall"] = "Read"
#get score on correct scale
combined$score = combined$score * 100
tapply(combined$score, list(combined$encoding, combined$direction), mean, na.omit = T)
##Check for outliers and weirdness here
summary(combined)
JOL3 = subset(combined,
combined$encoding == "JOL")
Read3 = subset(combined,
combined$encoding == "Read")
JOL.wide = cast(JOL3, id ~ direction, mean)
Read.wide = cast(Read3, id ~ direction, mean)
combined = subset(combined,
combined$id != "W10057641NS" & combined$id != "10068469SJ" & combined$id != "W_10132867_LAA" &
combined$id != "62f17b6b63bd9e6627a19956" & combined$id != "5a8b1ee2000dab00018cc7cd" &
combined$id != "62d43cee3d60ac98c1dcacc8" & combined$id != "63474e67a5fd298c6103c409" &
combined$id != "w963035" & combined$id != "5c2bb03b9fb36d000198e2d7" & combined$id != "w10162630_CAG" &
combined$id != "TaravionCosey" & combined$id != "w10055946")
####ANOVA####
model1 = ezANOVA(combined,
dv = score,
between = encoding,
within = direction,
wid = id,
type = 3,
detailed = T)
model1 #basically everything is sig!
####Post-hocs####
tapply(combined$score, combined$encoding, mean) #main effect of encoding
tapply(combined$score, combined$direction, mean) #main effect of direction
tapply(combined$score, list(combined$encoding, combined$direction), mean) #interaction
(tapply(combined$score, list(combined$encoding, combined$direction), sd) / sqrt(length(unique(combined$id)))) * 1.96
###break down direction main effect
combined.direction = cast(combined, id ~ direction, mean)
#F vs M
temp = t.test(combined.direction$F, combined.direction$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(combined.direction$F, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#U vs M
temp = t.test(combined.direction$M, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#Not surprisingly, everything is sig!
###Interaction
jol3 = subset(combined, combined$encoding == "JOL")
read3 = subset(combined, combined$encoding == "Read")
jol.ph = cast(jol3, id ~ direction, mean)
read.ph = cast(read3, id ~ direction, mean)
(apply(jol.ph[ , -1], 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph[ , -1], 2, sd) / sqrt(nrow(read.ph))) * 1.96
##forward
temp = t.test(jol.ph$F, read.ph$F, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Significant! p = .013
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#unrelated
temp = t.test(jol.ph$U, read.ph$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #Non-Sig
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#okay, so trending in the right direction!
##get ns after cleaning
##get N
nrow(jol.ph) #56
nrow(read.ph) #56
##How many from each platform?
jol4 = subset(jol3,
jol3$Platform == "Prolific")
length(unique(jol4$id)) #21
jol5 = subset(jol3,
jol3$Platform == "USM")
length(unique(jol5$id)) #35
read4 = subset(read3,
read3$Platform == "Prolific")
length(unique(read4$id)) #22
read5 = subset(read3,
read3$Platform == "USM")
length(unique(read5$id)) #34
####platform differences?####
combined2 = rbind(jol4, read4)
combined3 = rbind(jol5, read5)
tapply(combined2$score, list(combined2$encoding, combined2$direction), mean)
tapply(combined3$score, list(combined3$encoding, combined3$direction), mean) #Not really, its about 8% increase.
tapply(combined$score, list(combined$encoding, combined$direction), mean) #interaction
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity/3 Output/Ex 1 - Recall/USM/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity/3 Output/Ex 1 - Recall/USM/No-JOL")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #25
length(unique(Study$Username)) #23
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity/3 Output/Ex 1 - Recall/USM/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity/3 Output/Ex 1 - Recall/USM/No-JOL")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #25
length(unique(Study$Username)) #23
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
